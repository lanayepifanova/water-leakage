{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 5 \u2014 First model (interpretable baseline)\n",
        "\n",
        "This notebook trains a simple model on aggregated anomaly features.\n",
        "\n",
        "Inputs:\n",
        "- `data/features/anomaly_features.parquet`\n",
        "- `data/labels/segment_labels.csv` with columns: `segment_id`, `label` (1=break, 0=no break)\n",
        "\n",
        "Output:\n",
        "- `models/leak_risk_model.pkl`\n",
        "\n",
        "Metric:\n",
        "- Recall@K (default K=5%)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    import joblib\n",
        "except ImportError as exc:\n",
        "    raise SystemExit('Missing deps. Run: pip install pandas pyarrow scikit-learn joblib') from exc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load features\n",
        "features_path = Path('data/features/anomaly_features.parquet')\n",
        "if not features_path.exists():\n",
        "    raise SystemExit('Missing features. Run Step 4 to generate anomaly_features.parquet.')\n",
        "\n",
        "features = pd.read_parquet(features_path)\n",
        "\n",
        "# Load labels\n",
        "labels_path = Path('data/labels/segment_labels.csv')\n",
        "if not labels_path.exists():\n",
        "    raise SystemExit('Missing labels. Create data/labels/segment_labels.csv with segment_id,label.')\n",
        "\n",
        "labels = pd.read_csv(labels_path)\n",
        "\n",
        "df = features.merge(labels, on='segment_id', how='inner')\n",
        "if df.empty:\n",
        "    raise SystemExit('No labeled rows after merge. Check segment_id alignment.')\n",
        "\n",
        "df['label'] = df['label'].astype(int)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Feature columns (exclude ids and dates)\n",
        "drop_cols = {'break_id', 'segment_id', 'break_date', 'label'}\n",
        "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train baseline model\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=8,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "proba = model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "print('ROC AUC:', round(auc, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Recall@K\n",
        "def recall_at_k(y_true, y_score, k_frac=0.05):\n",
        "    n = len(y_true)\n",
        "    k = max(1, int(n * k_frac))\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    topk = np.array(y_true)[order[:k]]\n",
        "    return float(topk.sum() / max(1, np.sum(y_true)))\n",
        "\n",
        "r5 = recall_at_k(y_test.values, proba, k_frac=0.05)\n",
        "print('Recall@5%:', round(r5, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Save model\n",
        "out_path = Path('models/leak_risk_model.pkl')\n",
        "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "joblib.dump({\n",
        "    'model': model,\n",
        "    'feature_cols': feature_cols\n",
        "}, out_path)\n",
        "\n",
        "print(f'Wrote {out_path}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}