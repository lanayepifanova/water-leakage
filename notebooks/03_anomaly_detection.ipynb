{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4 \u2014 Turn imagery into anomaly signals\n",
        "\n",
        "This notebook:\n",
        "- builds a seasonal baseline per corridor segment (break buffer)\n",
        "- computes z-score anomalies for NDVI / NDWI (plus NDRE / RENDVI)\n",
        "- aggregates anomalies per segment (max, mean, persistence)\n",
        "\n",
        "Input: CSV exports from GEE in `data/imagery/sentinel2_time_series/`\n",
        "Output: `data/features/anomaly_features.parquet`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "except ImportError as exc:\n",
        "    raise SystemExit('Missing deps. Run: pip install pandas pyarrow') from exc\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load all exported CSVs from GEE\n",
        "data_dir = Path('data/imagery/sentinel2_time_series')\n",
        "csvs = sorted(data_dir.glob('*.csv'))\n",
        "if not csvs:\n",
        "    raise SystemExit('No CSVs found. Download the export(s) to data/imagery/sentinel2_time_series/.')\n",
        "\n",
        "df = pd.concat([pd.read_csv(p) for p in csvs], ignore_index=True)\n",
        "\n",
        "# Expect columns: break_id, break_date, month (YYYY-MM), kind, NDVI, NDWI, NDRE, RENDVI\n",
        "df['month'] = pd.to_datetime(df['month'] + '-01')\n",
        "df['month_num'] = df['month'].dt.month\n",
        "df['month_idx'] = df['month'].dt.year * 12 + df['month'].dt.month\n",
        "\n",
        "metrics = ['NDVI', 'NDWI', 'NDRE', 'RENDVI']\n",
        "print('Rows:', len(df))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Build seasonal baseline stats using baseline rows (same-month, prior years)\n",
        "baseline = df[df['kind'] == 'baseline'].copy()\n",
        "if baseline.empty:\n",
        "    raise SystemExit('No baseline rows found. Ensure your export includes baseline samples.')\n",
        "\n",
        "agg = {}\n",
        "for m in metrics:\n",
        "    agg[m] = ['mean', 'std']\n",
        "\n",
        "baseline_stats = baseline.groupby(['break_id', 'month_num']).agg(agg)\n",
        "baseline_stats.columns = [f'{col}_{stat}' for col, stat in baseline_stats.columns]\n",
        "baseline_stats = baseline_stats.reset_index()\n",
        "\n",
        "baseline_stats.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Compute z-score anomalies for window rows (6 months before -> 2 months after)\n",
        "window = df[df['kind'] == 'window'].copy()\n",
        "if window.empty:\n",
        "    raise SystemExit('No window rows found. Ensure your export includes the break window samples.')\n",
        "\n",
        "window = window.merge(baseline_stats, on=['break_id', 'month_num'], how='left')\n",
        "\n",
        "for m in metrics:\n",
        "    std = window[f'{m}_std']\n",
        "    valid_std = std.where(std > 1e-6)\n",
        "    window[f'{m}_z'] = (window[m] - window[f'{m}_mean']) / valid_std\n",
        "\n",
        "window[[f'{m}_z' for m in metrics]].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Aggregate anomalies per segment (break buffer)\n",
        "threshold = 2.0\n",
        "\n",
        "def max_consecutive(month_idx, flags):\n",
        "    if len(month_idx) == 0:\n",
        "        return 0\n",
        "    order = np.argsort(month_idx)\n",
        "    months = np.array(month_idx)[order]\n",
        "    flags = np.array(flags)[order]\n",
        "\n",
        "    max_run = 0\n",
        "    run = 0\n",
        "    last_m = None\n",
        "    for m, f in zip(months, flags):\n",
        "        if f and (last_m is None or m == last_m + 1):\n",
        "            run += 1\n",
        "        elif f:\n",
        "            run = 1\n",
        "        else:\n",
        "            run = 0\n",
        "        max_run = max(max_run, run)\n",
        "        last_m = m\n",
        "    return int(max_run)\n",
        "\n",
        "def per_segment(group):\n",
        "    out = {\n",
        "        'break_id': group['break_id'].iloc[0],\n",
        "        'segment_id': group['break_id'].iloc[0]\n",
        "    }\n",
        "    for m in metrics:\n",
        "        z = group[f'{m}_z']\n",
        "        out[f'{m.lower()}_z_max'] = z.max()\n",
        "        out[f'{m.lower()}_z_mean'] = z.mean()\n",
        "        out[f'{m.lower()}_persistence_months'] = max_consecutive(\n",
        "            group['month_idx'].tolist(), (z.abs() >= threshold).fillna(False).tolist()\n",
        "        )\n",
        "        out[f'{m.lower()}_persistence_days'] = out[f'{m.lower()}_persistence_months'] * 30\n",
        "    return pd.Series(out)\n",
        "\n",
        "features = window.groupby('break_id', sort=False).apply(per_segment).reset_index(drop=True)\n",
        "\n",
        "break_meta = df[['break_id', 'break_date']].drop_duplicates()\n",
        "features = features.merge(break_meta, on='break_id', how='left')\n",
        "\n",
        "features.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Save features\n",
        "out_path = Path('data/features/anomaly_features.parquet')\n",
        "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    features.to_parquet(out_path, index=False)\n",
        "    print(f'Wrote {out_path}')\n",
        "except Exception as exc:\n",
        "    raise SystemExit('Failed to write parquet. Install pyarrow: pip install pyarrow') from exc\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}